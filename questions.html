<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <link rel="stylesheet" type="text/css" href="gameoflife.css">
    <link rel="stylesheet" type="text/css" href="link.css">
    <link rel="stylesheet" type="text/css" href="questions.css">
    <script src="questions.js"></script>
    <script src="gameoflife.js"></script>
  </head>
  <body>
    <div id="mainDiv">
      <h1>Q's without A's</h1>
      <ul>
	<li>
	  Many of the most intelligent animals in the world have <a href="spindle.pdf">independently</a> evolved spindle neurons, which connect distant regions of the brain. Does this suggest that the coherency brought by small-world topologies is ideal for intelligent networks, or merely that animals need brains which can quickly react to threat stimuli?
	  <p><a href="neural_topology.pdf">Recent studies</a> have shown that these topologies are present in neural microstructures as well, supporting the hypothesis that speed is not the sole benefit. In terms of ANNs, it stands to reason that fast information propagation would generally lend itself to fast training rates. This finds analogy in the acceleration of scientific progress with the advent of near-instantaneous global communication.</p>
	</li>
	<li>
	  Is there a pattern to the deletions made when applying <a href="le_cun.pdf">Optimal Brain Damage</a> to the neurons or synapses of a fully-trained, complete RNN?<p>Such a pattern could point to smaller, sparser topologies which closely approximate the ideal of a complete graph.</p>
	</li>
	<li>
	  Is there a space which orders cellular automata according to how chaotically they behave?
	  <p><a href="langton.pdf">Langton</a> devised the &lambda; parameter in an attempt to do so, but his measure ignores the subtlety of state transitions; for instance, 000 &#8594; 0 should certainly be interpreted differently than 101 &#8594; 0.</p>
	  <p>The <a href="https://github.com/GeoffChurch/CellularAutomata/blob/master/automaton.py#L64">tmat</a> can be a useful tool for interpreting rules. The tmat of a rule is the matrix M where M[i][j] is the number of input scenarios in which a cell in state i results in a cell becoming or remaining in state j. Given a prior PDF over cell states, multiplying by the tmat yields an approximation of the posterior. In a binary automaton, the sum of the top row divided by the rule length equals the &lambda; parameter, so perhaps the standard deviation of sums over the length of the rule would be a viable extension of the &lambda; parameter to higher dimensions. However, the minor diagonal records how many ways a cell state can remain the same, which more accurately captures what we think of as order and, inversely, chaos. Ordering automata by the determinants of their tmats also works well, but this is largely because rules with similar behaviors tend to have similar tmats, and the determinant in this context is essentially a locality-sensitive hash function.</p>
	  <p>
	    Although the tmat is useful for getting a vague idea of the state distribution, it ignores the difference between 110 &#8594; 0 and 101 &#8594; 0, which may entail very different outcomes in the next timestep. Since an a-ary CA's cell function has i inputs, not just 1, a more accurate representation would be a matrix of possible transitions over the a<sup>i</sup> different i-tuples.
	  </p>
	</li>
	<li>
	  Can the chaos of a dynamical system be determined from the lengths of its orbits?
	  <p>Given a Fourier analysis of a rule's <a href="https://github.com/GeoffChurch/CellularAutomata/blob/master/automaton.py#L11">state transition matrix</a>, it's intuitive that the variance of its real components would be a good measure of how predictable (un-chaotic) the rule is. <a href="spectral.pdf">Ninagawa</a> and many others have analyzed the actual patterns generated by rules starting from specific seeds. On the other hand, this approach is perpendicular, operating upon the entire state space over a single time step. Essentially, it's measuring how injective the rule is, how many states end up in the same sinks as other states. Given c cells with a states each, setting n equal to a<sup>c</sup> ensures that each state will have fallen into orbit, a<sup>c</sup> being the length of the longest possible orbit.</p>
	  <p>This is prohibitively expensive to compute for all but the smallest state spaces, but we can at least improve it from &Theta;(sa<sup>2c</sup>) to &Theta;(sa<sup>c</sup>) with dynamic programming, where s is the complexity of computing the successor of a single state, equal to c in the case of cellular automata. Drastic mitigation of the complexity is possible if the system is computationally reduceable.</p>
	  <p><a href="https://github.com/GeoffChurch/CellularAutomata/blob/master/automaton.py#L48">This method</a> achieves the best of both approaches (orbit periodicity for all possible states) in the improved time and can easily be extended to record the orbit itself without touching the complexity.</p>
	  <p>
	    There is at least one caveat in that variance alone is not a monotonically good indicator of chaos, as a simple counter, or any other system with a single, ubiquitous orbit, would maximize variance. Instead, we can aim to find a middle ground which takes into consideration both the number of orbits and the lengths of those orbits. If we view this as an area-under-the-curve problem, the minima are the two cases where:</p>
	    <ol>
	      <li>
		number of orbits = number of system states; orbit length = 1
	      </li>
	      <li>
		number of orbits = 1; orbit length = number of system states
	      </li>
	    </ol>
	    <p>
	    and the maximum is the case where number of orbits = orbit length = &radic;(number of system states).
	  </p>
	</li>
      </ul>
      <div class="link" onclick="window.location='..';">back</div>
    </div>
  </body>
</html>
